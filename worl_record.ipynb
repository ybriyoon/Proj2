{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup as bs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.worldathletics.org/records/by-category/world-records'\n",
    "#Create a handle, page, to handle the contents of the website\n",
    "page = requests.get(url)\n",
    "#Store the contents of the website under doc\n",
    "soup = bs(page.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<th>\n                    Discipline\n                </th>, <th>\n                    Progression\n                </th>, <th>\n                    Perf\n                </th>, <th>\n                        Wind\n                    </th>, <th>\n                    Competitor\n                </th>, <th>\n                    DOB\n                </th>, <th>\n                    Country\n                </th>, <th>\n                    Venue\n                </th>, <th>\n                    Date\n                </th>, <th>\n                    Discipline\n                </th>, <th>\n                    Progression\n                </th>, <th>\n                    Perf\n                </th>, <th>\n                        Wind\n                    </th>, <th>\n                    Competitor\n                </th>, <th>\n                    DOB\n                </th>, <th>\n                    Country\n                </th>, <th>\n                    Venue\n                </th>, <th>\n                    Date\n                </th>, <th>\n                    Discipline\n                </th>, <th>\n                    Progression\n                </th>, <th>\n                    Perf\n                </th>, <th>\n                        Wind\n                    </th>, <th>\n                    Competitor\n                </th>, <th>\n                    DOB\n                </th>, <th>\n                    Country\n                </th>, <th>\n                    Venue\n                </th>, <th>\n                    Date\n                </th>, <th>\n                    Discipline\n                </th>, <th>\n                    Progression\n                </th>, <th>\n                    Perf\n                </th>, <th>\n                        Wind\n                    </th>, <th>\n                    Competitor\n                </th>, <th>\n                    DOB\n                </th>, <th>\n                    Country\n                </th>, <th>\n                    Venue\n                </th>, <th>\n                    Date\n                </th>, <th>\n                    Discipline\n                </th>, <th>\n                    Progression\n                </th>, <th>\n                    Perf\n                </th>, <th>\n                        Wind\n                    </th>, <th>\n                    Competitor\n                </th>, <th>\n                    DOB\n                </th>, <th>\n                    Country\n                </th>, <th>\n                    Venue\n                </th>, <th>\n                    Date\n                </th>]\n"
     ]
    }
   ],
   "source": [
    "tables_out= soup.find(\"div\", {\"id\": \"womenoutdoor\"})\n",
    "tables_in= soup.find(\"div\", {\"id\": \"womenindoor\"})\n",
    "\n",
    "tableheader_out= tables_out.find_all('th')\n",
    "tableheader_in= tables_in.find_all('tr')\n",
    "\n",
    "table= soup.find_all('th')\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                    Discipline\n                \n\n                    Progression\n                \n\n                    Perf\n                \n\n                        Wind\n                    \n\n                    Competitor\n                \n\n                    DOB\n                \n\n                    Country\n                \n\n                    Venue\n                \n\n                    Date\n                \n"
     ]
    }
   ],
   "source": [
    "for tr in tables_out.find_all('tr'):\n",
    "    data=[]\n",
    "    \n",
    "    for th in tr.find_all('th'):\n",
    "        print(th.text)\n",
    "    #     data.append(th.text)\n",
    "    \n",
    "    # if(data):\n",
    "    #     print(\"headers: {}\".format(','.join(data)))\n",
    "    #     csv_writer.writerow(data)\n",
    "    #     continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n100 Metres\n\n\n200 Metres\n\n\n400 Metres\n\n\n800 Metres\n\n\n1000 Metres\n\n\n1500 Metres\n\n\nOne Mile\n\n\n2000 Metres\n\n\n3000 Metres\n\n\n5000 Metres\n\n\n5 Kilometres\n\n\n5 Kilometres\n\n\n10,000 Metres\n\n\n10 Kilometres\n\n\n10 Kilometres\n\n\n20,000 Metres\n\n\nOne Hour\n\n\nHalf Marathon\n\n\nHalf Marathon\n\n\nHalf Marathon\n\n\n25,000 Metres\n\n\n30,000 Metres\n\n\nMarathon\n\n\nMarathon\n\n\n100 Kilometres\n\n\n3000 Metres Steeplechase\n\n\n100 Metres Hurdles\n\n\n400 Metres Hurdles\n\n\nHigh Jump\n\n\nPole Vault\n\n\nLong Jump\n\n\nTriple Jump\n\n\nShot Put\n\n\nDiscus Throw\n\n\nHammer Throw\n\n\nJavelin Throw\n\n\nHeptathlon\n\n\nDecathlon\n\n\n10,000 Metres Race Walk\n\n\n20,000 Metres Race Walk\n\n\n20 Kilometres Race Walk\n\n\n50 Kilometres Race Walk\n\n\n4x100 Metres Relay\n\n\n4x200 Metres Relay\n\n\n4x400 Metres Relay\n\n\n4x800 Metres Relay\n\n\n4x1500 Metres Relay\n\n\nRoad Relay\n\n\nDistance Medley Relay\n\n"
     ]
    }
   ],
   "source": [
    " \n",
    "for td in tables_out.find_all('td', {'data-th':\"DISCIPLINE\"}):\n",
    "    print(td.text)\n",
    "    # data.append(td.text)\n",
    "    \n",
    "    # if(data):\n",
    "    #     print(\"DISCIPLINE: {}\".format(','.join(data)))\n",
    "    #     csv_writer.writerow(data)\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\n\n                        10.49   \n                    \n\n\n\n\n                        21.34   \n                    \n\n\n\n\n                        47.60   \n                    \n\n\n\n\n                        1:53.28   \n                    \n\n\n\n\n                        2:28.98   \n                    \n\n\n\n\n                        3:50.07   \n                    \n\n\n\n\n                        4:12.33   \n                    \n\n\n\n\n                        5:23.75   (i)\n                    \n\n\n\n\n                        8:06.11   \n                    \n\n\n\n\n                        14:06.62   \n                    \n\n\n\n\n                        14:48  Mx \n                    \n\n\n\n\n                        14:44 Wo  \n                    \n\n\n\n\n                        29:17.45   \n                    \n\n\n\n\n                        30:29 Wo  \n                    \n\n\n\n\n                        29:43  Mx \n                    \n\n\n\n\n                        1:05:26.6h #   \n                    \n\n\n\n\n                        18930   \n                    \n\n\n\n\n                        1:05:34 Wo  \n                    \n\n\n\n\n                        1:05:16 Wo  *\n                    \n\n\n\n\n                        1:04:31  Mx \n                    \n\n\n\n\n                        1:27:05.9h #   \n                    \n\n\n\n\n                        1:45:50.0h #   \n                    \n\n\n\n\n                        2:17:01 Wo  \n                    \n\n\n\n\n                        2:14:04  Mx \n                    \n\n\n\n\n                        6:33:11  Mx \n                    \n\n\n\n\n                        8:44.32   \n                    \n\n\n\n\n                        12.20   \n                    \n\n\n\n\n                        52.16   \n                    \n\n\n\n\n                        2.09   \n                    \n\n\n\n\n                        5.06   \n                    \n\n\n\n\n                        7.52   \n                    \n\n\n\n\n                        15.50   \n                    \n\n\n\n\n                        22.63   \n                    \n\n\n\n\n                        76.80   \n                    \n\n\n\n\n                        82.98   \n                    \n\n\n\n\n                        72.28   \n                    \n\n\n\n\n                        7291   \n                    \n\n\n\n\n                        8358   \n                    \n\n\n\n\n                        41:56.23   \n                    \n\n\n\n\n                        1:26:52.3h   \n                    \n\n\n\n\n                        1:24:38   \n                    \n\n\n\n\n                        3:59:15   \n                    \n\n\n\n\n                        40.82   \n                    \n\n\n\n\n                        1:27.46   \n                    \n\n\n\n\n                        3:15.17   \n                    \n\n\n\n\n                        7:50.17   \n                    \n\n\n\n\n                        16:27.02   \n                    \n\n\n\n\n                        2:11:41   \n                    \n\n\n\n\n                        10:36.50   \n                    \n"
     ]
    }
   ],
   "source": [
    "for td in tables_out.find_all('td', {'data-th':\"PERF\"}):\n",
    "    print(td.text)\n",
    "\n",
    "    # data.append(td.text.strip())\n",
    "    \n",
    "    # if(data):\n",
    "    #     print(\"PERF: {}\".format(','.join(data)))\n",
    "    #     csv_writer.writerow(data)\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                            0.0\n                        \n\n                            +1.3\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                            +0.3\n                        \n\n\n\n\n\n\n\n                            +1.4\n                        \n\n                            +0.9\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for td in tables_out.find_all('td', {'data-th':\"WIND\"}):\n",
    "    print(td.text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nFlorence GRIFFITH-JOYNER\n\n\nFlorence GRIFFITH-JOYNER\n\n\nMarita KOCH\n\n\nJarmila KRATOCHVÍLOVÁ\n\n\nSvetlana MASTERKOVA\n\n\nGenzebe DIBABA\n\n\nSifan HASSAN\n\n\nGenzebe DIBABA\n\n\nJunxia WANG\n\n\nLetesenbet GIDEY\n\n\nCaroline Chepkoech KIPKIRUI\n\n\nSifan HASSAN\n\n\nAlmaz AYANA\n\n\nAsmae LEGHZAOUI\n\n\nJoyciline JEPKOSGEI\n\n\nTegla LOROUPE\n\n\nSifan HASSAN\n\n\nPeres JEPCHIRCHIR\n\n\nPeres JEPCHIRCHIR\n\n\nAbabel YESHANEH\n\n\nTegla LOROUPE\n\n\nTegla LOROUPE\n\n\nMary Jepkosgei KEITANY\n\n\nBrigid KOSGEI\n\n\nTomoe ABE\n\n\nBeatrice CHEPKOECH\n\n\nKendra HARRISON\n\n\nDalilah MUHAMMAD\n\n\nStefka KOSTADINOVA\n\n\nYelena ISINBAYEVA\n\n\nGalina CHISTYAKOVA\n\n\nInessa KRAVETS\n\n\nNatalia LISOVSKAYA\n\n\nGabriele REINSCH\n\n\nAnita WŁODARCZYK\n\n\nBarbora ŠPOTÁKOVÁ\n\n\nJackie JOYNER-KERSEE\n\n\nAustra SKUJYTÉ\n\n\nNadezhda RYASHKINA\n\n\nOlimpiada IVANOVA\n\n\nHong LIU\n\n\nHong LIU\n\n\nUnited States\n                        \n\nUnited States Blue\n                        \n\nSoviet Union\n                        \n\nSoviet Union\n                        \n\nNike/Bowerman Track Club\n                        \n\nPR of China\n                        \n\nUnited States\n                        \n"
     ]
    }
   ],
   "source": [
    "for td in tables_out.find_all('td', {'data-th':\"COMPETITOR\"}):\n",
    "    print(td.text)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                        21 DEC 1959\n                    \n\n                        21 DEC 1959\n                    \n\n                        18 FEB 1957\n                    \n\n                        26 JAN 1951\n                    \n\n                        17 JAN 1968\n                    \n\n                        08 FEB 1991\n                    \n\n                        01 JAN 1993\n                    \n\n                        08 FEB 1991\n                    \n\n                        09 JAN 1973\n                    \n\n                        20 MAR 1998\n                    \n\n                        26 MAY 1994\n                    \n\n                        01 JAN 1993\n                    \n\n                        21 NOV 1991\n                    \n\n                        30 AUG 1976\n                    \n\n                        08 DEC 1993\n                    \n\n                        09 MAY 1973\n                    \n\n                        01 JAN 1993\n                    \n\n                        27 SEP 1993\n                    \n\n                        27 SEP 1993\n                    \n\n                        22 JUL 1991\n                    \n\n                        09 MAY 1973\n                    \n\n                        09 MAY 1973\n                    \n\n                        18 JAN 1982\n                    \n\n                        20 FEB 1994\n                    \n\n                        13 AUG 1971\n                    \n\n                        06 JUL 1991\n                    \n\n                        18 SEP 1992\n                    \n\n                        07 FEB 1990\n                    \n\n                        25 MAR 1965\n                    \n\n                        03 JUN 1982\n                    \n\n                        26 JUL 1962\n                    \n\n                        05 OCT 1966\n                    \n\n                        16 JUL 1962\n                    \n\n                        23 SEP 1963\n                    \n\n                        08 AUG 1985\n                    \n\n                        30 JUN 1981\n                    \n\n                        03 MAR 1962\n                    \n\n                        12 AUG 1979\n                    \n\n                        22 JAN 1967\n                    \n\n                        29 AUG 1970\n                    \n\n                        12 MAY 1987\n                    \n\n                        12 MAY 1987\n                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for td in tables_out.find_all('td', {'data-th':\"DOB\"}):\n",
    "    print(td.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n                        USA\n                    \n\n\n                        USA\n                    \n\n\n                        GDR\n                    \n\n\n                        TCH\n                    \n\n\n                        RUS\n                    \n\n\n                        ETH\n                    \n\n\n                        NED\n                    \n\n\n                        ETH\n                    \n\n\n                        CHN\n                    \n\n\n                        ETH\n                    \n\n\n                        KEN\n                    \n\n\n                        NED\n                    \n\n\n                        ETH\n                    \n\n\n                        MAR\n                    \n\n\n                        KEN\n                    \n\n\n                        KEN\n                    \n\n\n                        NED\n                    \n\n\n                        KEN\n                    \n\n\n                        KEN\n                    \n\n\n                        ETH\n                    \n\n\n                        KEN\n                    \n\n\n                        KEN\n                    \n\n\n                        KEN\n                    \n\n\n                        KEN\n                    \n\n\n                        JPN\n                    \n\n\n                        KEN\n                    \n\n\n                        USA\n                    \n\n\n                        USA\n                    \n\n\n                        BUL\n                    \n\n\n                        RUS\n                    \n\n\n                        URS\n                    \n\n\n                        UKR\n                    \n\n\n                        URS\n                    \n\n\n                        GDR\n                    \n\n\n                        POL\n                    \n\n\n                        CZE\n                    \n\n\n                        USA\n                    \n\n\n                        LTU\n                    \n\n\n                        URS\n                    \n\n\n                        RUS\n                    \n\n\n                        CHN\n                    \n\n\n                        CHN\n                    \n\n\n                        USA\n                    \n\n\n                        USA\n                    \n\n\n                        URS\n                    \n\n\n                        URS\n                    \n\n\n                        USA\n                    \n\n\n                        CHN\n                    \n\n\n                        USA\n                    \n"
     ]
    }
   ],
   "source": [
    "for td in tables_out.find_all('td', {'data-th':\"COUNTRY\"}):\n",
    "    print(td.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "                        Indianapolis, IN (USA)\n",
      "                    \n",
      "\n",
      "                        Olympic Stadium, Jamsil, Seoul (KOR)\n",
      "                    \n",
      "\n",
      "                        Bruce Stadium, Canberra (AUS)\n",
      "                    \n",
      "\n",
      "                        München (GER)\n",
      "                    \n",
      "\n",
      "                        Bruxelles (BEL)\n",
      "                    \n",
      "\n",
      "                        Stade Louis II, Monaco (MON)\n",
      "                    \n",
      "\n",
      "                        Stade Louis II, Monaco (MON)\n",
      "                    \n",
      "\n",
      "                        Sabadell (ESP)\n",
      "                    \n",
      "\n",
      "                        Beijing (CHN)\n",
      "                    \n",
      "\n",
      "                        Estadio de Atletismo del Turia, Valencia (ESP)\n",
      "                    \n",
      "\n",
      "                        Praha (CZE)\n",
      "                    \n",
      "\n",
      "                        Monaco (MON)\n",
      "                    \n",
      "\n",
      "                        Estádio Olímpico, Rio de Janeiro (BRA)\n",
      "                    \n",
      "\n",
      "                        New York, NY (USA)\n",
      "                    \n",
      "\n",
      "                        Praha (CZE)\n",
      "                    \n",
      "\n",
      "                        Borgholzhausen (GER)\n",
      "                    \n",
      "\n",
      "                        Boudewijnstadion, Bruxelles (BEL)\n",
      "                    \n",
      "\n",
      "                        Praha (CZE)\n",
      "                    \n",
      "\n",
      "                        Gdynia (POL)\n",
      "                    \n",
      "\n",
      "                        Ras Al Khaimah (UAE)\n",
      "                    \n",
      "\n",
      "                        Mengerskirchen (GER)\n",
      "                    \n",
      "\n",
      "                        Warstein (GER)\n",
      "                    \n",
      "\n",
      "                        London (GBR)\n",
      "                    \n",
      "\n",
      "                        Chicago, IL (USA)\n",
      "                    \n",
      "\n",
      "                        Lake Saroma (JPN)\n",
      "                    \n",
      "\n",
      "                        Stade Louis II, Monaco (MON)\n",
      "                    \n",
      "\n",
      "                        Olympic Stadium, London (GBR)\n",
      "                    \n",
      "\n",
      "                        Khalifa International Stadium, Doha (QAT)\n",
      "                    \n",
      "\n",
      "                        Stadio Olimpico, Roma (ITA)\n",
      "                    \n",
      "\n",
      "                        Letzigrund, Zürich (SUI)\n",
      "                    \n",
      "\n",
      "                        Leningrad (URS)\n",
      "                    \n",
      "\n",
      "                        Ullevi Stadium, Göteborg (SWE)\n",
      "                    \n",
      "\n",
      "                        Moskva (URS)\n",
      "                    \n",
      "\n",
      "                        Neubrandenburg (GDR)\n",
      "                    \n",
      "\n",
      "                        Stadion PGE Narodowy, Warszawa (POL)\n",
      "                    \n",
      "\n",
      "                        Gottlieb-Daimler Stadion, Stuttgart (GER)\n",
      "                    \n",
      "\n",
      "                        Olympic Stadium, Jamsil, Seoul (KOR)\n",
      "                    \n",
      "\n",
      "                        Columbia, MO (USA)\n",
      "                    \n",
      "\n",
      "                        Seattle, WA (USA)\n",
      "                    \n",
      "\n",
      "                        Brisbane (AUS)\n",
      "                    \n",
      "\n",
      "                        La Coruña (ESP)\n",
      "                    \n",
      "\n",
      "                        Huangshan (CHN)\n",
      "                    \n",
      "\n",
      "                        Olympic Stadium, London (GBR)\n",
      "                    \n",
      "\n",
      "                        Philadelphia, PA (USA)\n",
      "                    \n",
      "\n",
      "                        Olympic Stadium, Jamsil, Seoul (KOR)\n",
      "                    \n",
      "\n",
      "                        Moskva (URS)\n",
      "                    \n",
      "\n",
      "                        Jesuit High School Track, Portland, OR (USA)\n",
      "                    \n",
      "\n",
      "                        Beijing (CHN)\n",
      "                    \n",
      "\n",
      "                        T. Robinson Stadium, Nassau (BAH)\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "for td in tables_out.find_all('td', {'data-th':\"VENUE\"}):\n",
    "  print(td.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                        16 JUL 1988\n                    \n\n                        29 SEP 1988\n                    \n\n                        06 OCT 1985\n                    \n\n                        26 JUL 1983\n                    \n\n                        23 AUG 1996\n                    \n\n                        17 JUL 2015\n                    \n\n                        12 JUL 2019\n                    \n\n                        07 FEB 2017\n                    \n\n                        13 SEP 1993\n                    \n\n                        07 OCT 2020\n                    \n\n                        08 SEP 2018\n                    \n\n                        17 FEB 2019\n                    \n\n                        12 AUG 2016\n                    \n\n                        08 JUN 2002\n                    \n\n                        09 SEP 2017\n                    \n\n                        03 SEP 2000\n                    \n\n                        04 SEP 2020\n                    \n\n                        05 SEP 2020\n                    \n\n                        17 OCT 2020\n                    \n\n                        21 FEB 2020\n                    \n\n                        21 SEP 2002\n                    \n\n                        06 JUN 2003\n                    \n\n                        23 APR 2017\n                    \n\n                        13 OCT 2019\n                    \n\n                        25 JUN 2000\n                    \n\n                        20 JUL 2018\n                    \n\n                        22 JUL 2016\n                    \n\n                        04 OCT 2019\n                    \n\n                        30 AUG 1987\n                    \n\n                        28 AUG 2009\n                    \n\n                        11 JUN 1988\n                    \n\n                        10 AUG 1995\n                    \n\n                        07 JUN 1987\n                    \n\n                        09 JUL 1988\n                    \n\n                        28 AUG 2016\n                    \n\n                        13 SEP 2008\n                    \n\n                        24 SEP 1988\n                    \n\n                        15 APR 2005\n                    \n\n                        24 JUL 1990\n                    \n\n                        06 SEP 2001\n                    \n\n                        06 JUN 2015\n                    \n\n                        09 MAR 2019\n                    \n\n                        10 AUG 2012\n                    \n\n                        29 APR 2000\n                    \n\n                        01 OCT 1988\n                    \n\n                        05 AUG 1984\n                    \n\n                        31 JUL 2020\n                    \n\n                        28 FEB 1998\n                    \n\n                        02 MAY 2015\n                    \n"
     ]
    }
   ],
   "source": [
    "for td in tables_out.find_all('td', {'data-th':\"DATE\"}):\n",
    "    print(td.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}